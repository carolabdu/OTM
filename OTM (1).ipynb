{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Trabalho de Otimização\n",
        "Carolina Frank Abdu e Rafaella Lenzi Romano"
      ],
      "metadata": {
        "id": "wLIk98EYsT_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bibliotecas\n",
        "\n"
      ],
      "metadata": {
        "id": "s74LGdNTsb6m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EONNu07osPoU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sympy as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Função 1:\n",
        "$$\n",
        "\\min f(x) = \\sum_{i=1}^{6} \\left( 100 (x_{i+1} - x_i^2)^2 + (1 - x_i)^2 \\right)\n",
        "\\quad \\text{sujeito a} \\quad x \\in \\mathbb{R}^7\n",
        "$$\n",
        "\n",
        "Podemos notar que as parcelas do nosso somatório são valores não negativos, ou seja, o menor valor possível nessa primeira análise seria o zero. Além disso, como queremos minimizar, podemos analisar cada parcela separadamente. Como há dependência de valores, vamos analisar a parcela: $$100 (x_{2} - x_1^2)^2 + (1 - x_1)^2 $$ e depois prosseguir com as próximas.  \n",
        "\n",
        "Gráfico : https://www.geogebra.org/3d/qjszp48r\n",
        "\n",
        "##Gradiente\n",
        "Vamos encontrar os pontos críticos da função $$100 (x_{2} - x_1^2)^2 + (1 - x_1)^2 $$\n",
        "\n",
        "\n",
        "   $$\n",
        "   \\frac{\\partial f}{\\partial x_1} = -400 x_1 (x_2 - x_1^2) - 2 (1 - x_1)\n",
        "   $$\n",
        "\n",
        "\n",
        "   $$\n",
        "   \\frac{\\partial f}{\\partial x_2} = 200 (x_2 - x_1^2)\n",
        "   $$\n",
        "\n",
        "Pelo segundo gradiente temos que $$x_2=x_1^2,$$ substituindo no primeiro gradiente, podemos notar o ponto crítico (1, 1).\n",
        "\n",
        "####Observação:\n",
        "Como no ponto crítico encontrado $x_1=x_2$, podemos analisar apenas essa primeira parcela já que as outras serão iguais também.\n",
        "\n",
        "##Hessiana\n",
        "No ponto (1,1), a Hessiana H é:\n",
        "\n",
        "\\begin{bmatrix}\n",
        "1200x_1^2 - 400x_2 + 2 & -400x_1\\\\\n",
        "-400x_1 & 200\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "802 & -400\\\\\n",
        "-400 & 200\n",
        "\\end{bmatrix}\n",
        "\n",
        "Como a matriz é definida positiva, podemos afirmar que (1,1) é minimizador local estrito."
      ],
      "metadata": {
        "id": "ghK43f06s3Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func1(x):\n",
        "  x = np.array(x)\n",
        "  f1 = 100 * (x[1] - x[0]**2)**2 + (1 - x[0])**2\n",
        "  return f1\n",
        "\n",
        "def grad_1(x):\n",
        "  grad = np.zeros(2)\n",
        "  grad[0] = -400 * x[0] * (x[1] - x[0]**2) + 2 * (x[0] - 1)\n",
        "  grad[1] = 200 * (x[1] - x[0]**2)\n",
        "  return grad\n",
        "\n",
        "def hess_1(x):\n",
        "  hess = np.zeros((2,2))\n",
        "  hess[0, 0] = 1200 * x[0]**2 - 400 * x[1] + 2\n",
        "  hess[0, 1] = hess[1, 0] = -400 * x[0]\n",
        "  hess[1, 1] = 200\n",
        "  return hess\n",
        "\n",
        "def funcao_1(x):\n",
        "  x = np.array(x)\n",
        "  f= 0\n",
        "  for i in range(0, 6):\n",
        "    f += 100 * (x[i+1] - x[i]**2)**2 + (1 - x[i])**2\n",
        "  return f\n",
        "\n",
        "def gradiente_1(x):\n",
        "  grad = np.zeros(7)\n",
        "  grad[0] = -400 * x[0] * (x[1] - x[0]**2) + 2 * (x[0] - 1)\n",
        "  for i in range(1, 6):\n",
        "    grad[i] = -400 * x[i] * (x[i+1] - x[i] )+ 2*(x[i]-1) + 200 * (x[i] - x[i-1]**2)\n",
        "  grad[6] = 200 * (x[6] - x[5]**2)\n",
        "  return grad\n",
        "\n",
        "def hesssiana_1(x):\n",
        "  hess = np.zeros((7, 7))\n",
        "\n",
        "  # Preencher a matriz Hessiana\n",
        "  hess[0, 0] = 1200 * x[0]**2 - 400 * x[1] + 2\n",
        "  hess[0, 1] = -400 * x[0]\n",
        "\n",
        "  for i in range(1, 6):\n",
        "      hess[i, i-1] = -400 * x[i-1]\n",
        "      hess[i, i] = 1200 * x[i]**2 - 400 * x[i+1] + 202\n",
        "      hess[i, i+1] = -400 * x[i]\n",
        "\n",
        "  hess[6, 5] = -400 * x[5]\n",
        "  hess[6, 6] = 200\n",
        "\n",
        "  return hess\n",
        "\n",
        "def definida_positiva(x):\n",
        "  A = np.array(hess_1(x))\n",
        "  autovalores = np.linalg.eigvals(A)\n",
        "  if np.all(autovalores > 0):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "print(func1([1,1]))\n",
        "print(grad_1([1,1]))\n",
        "print(hess_1([1,1]))\n",
        "print(funcao_1([1,1,1,1,1,1,1]))\n",
        "print(hesssiana_1([1,1,1,1,1,1,1]))\n",
        "print(gradiente_1([1,1,1,1,1,1,1]))\n",
        "print(gradiente_1([0.82940915, 0.78198975, 0.80022798, 0.87047686, 0.90832119,\n",
        "       0.96949339, 0.98887151]))\n",
        "\n"
      ],
      "metadata": {
        "id": "IMb6pCgztcQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "384ce5cc-c716-442c-b71b-6f8d0f3daea7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[0. 0.]\n",
            "[[ 802. -400.]\n",
            " [-400.  200.]]\n",
            "0\n",
            "[[ 802. -400.    0.    0.    0.    0.    0.]\n",
            " [-400. 1002. -400.    0.    0.    0.    0.]\n",
            " [   0. -400. 1002. -400.    0.    0.    0.]\n",
            " [   0.    0. -400. 1002. -400.    0.    0.]\n",
            " [   0.    0.    0. -400. 1002. -400.    0.]\n",
            " [   0.    0.    0.    0. -400. 1002. -400.]\n",
            " [   0.    0.    0.    0.    0. -400.  200.]]\n",
            "[0. 0. 0. 0. 0. 0. 0.]\n",
            "[-31.5502595   12.67317831  14.8584104   32.58631631   7.70928542\n",
            "  21.31340424   9.79081535]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Função 2:\n",
        "$$\n",
        "\\min f(x) = \\sum_{i=1}^{100} \\left( x_i^4 - 16 x_i^2 + 5 x_i \\right)\n",
        "\\quad \\text{sujeito a} \\quad x \\in \\mathbb{R}^{100}\n",
        "$$\n",
        "\n",
        "Podemos minimizar cada uma das parcelas, pois elas são independentes. Além disso, terão o mesmo valor. Assim, o problema se reduz a encontrar o mínimo da função:\n",
        "$$f(x) = x^4 -16x^2+5x$$\n",
        "\n",
        "\n",
        "##Gradiente\n",
        "\n",
        "   $$\n",
        "   \\frac{\\partial f}{\\partial x_i} = 4 x^3 -32x +5\n",
        "   $$\n",
        "\n",
        "Gráfico :\n",
        "https://www.geogebra.org/graphing/kmhujh39\n",
        "\n",
        "Pontos críticos encontrados:\n",
        "x = -2,903; x = 2,747; x= 0,157"
      ],
      "metadata": {
        "id": "iedyJM3FvS9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func2(x):\n",
        "  x = np.array(x)\n",
        "  f2 = x[0]**4 - 16 * x[0]**2 + 5 * x[0]\n",
        "  return f2\n",
        "\n",
        "def grad_2(x):\n",
        "  grad = np.zeros(1)\n",
        "  grad[0] = 4 * x[0]**3 - 32 * x[0] + 5\n",
        "  return grad\n",
        "\n",
        "def hess_2(x):\n",
        "  hess = np.zeros((1, 1))\n",
        "  hess[0, 0] += 12 * x[0]**2 - 32\n",
        "  return hess\n",
        "\n",
        "def definida_positiva(x):\n",
        "  A = np.array(hess_2(x))\n",
        "  autovalores = np.linalg.eigvals(A)\n",
        "  if np.all(autovalores > 0):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "## Fazendo no R100:\n",
        "def funcao_2(x):\n",
        "  x = np.array(x)\n",
        "  f2 = 0\n",
        "  for i in range(0, 100):\n",
        "    f2 += x[i]**4 - 16 * x[i]**2 + 5 * x[i]\n",
        "  return f2\n",
        "\n",
        "def gradiente_2(x):\n",
        "  grad = np.zeros(100)\n",
        "  for i in range(0, 100):\n",
        "    grad[i] = 4 * x[i]**3 - 32 * x[i] + 5\n",
        "  return grad\n",
        "\n",
        "def hessiana_2(x):\n",
        "  h = np.zeros((100, 100))\n",
        "  for i in range(0, 100):\n",
        "    h[i, i] += 12 * x[i]**2 - 32\n",
        "  return h\n",
        "\n",
        "def p():\n",
        "  print(func2([0.157]))\n",
        "  print(grad_2([0.157]))\n",
        "  print(hess_2([0.157]))\n",
        "  print(definida_positiva([0.157]))\n",
        "\n",
        "  print(func2([2.747]))\n",
        "  print(grad_2([2.747]))\n",
        "  print(hess_2([2.747]))\n",
        "  print(definida_positiva([2.747]))\n",
        "\n",
        "  print(func2([-2.903]))\n",
        "  print(grad_2([-2.903]))\n",
        "  print(hess_2([-2.903]))\n",
        "  print(definida_positiva([-2.903]))"
      ],
      "metadata": {
        "id": "FPOup4gfxRWj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Função 3:\n",
        "$$\n",
        "\\min f(x) = (x_1^2 + x_2 - 11)^2 + (x_1 + x_2^2 - 7)^2\n",
        "\\quad \\text{sujeito a} \\quad x \\in \\mathbb{R}^2\n",
        "$$\n",
        "\n",
        "Podemos observar que o mínimo será zero, já que temos a soma de duas funções não negativas. Um estudo dos candidatos ao mínimo, usando essa simplificação pode ser observado no gráfico a seguir: https://www.geogebra.org/calculator/eh33nvhk\n",
        "\n",
        "##Gradiente\n",
        "$$\n",
        "   \\frac{\\partial f}{\\partial x_1} = 4x_1(x_1^2 + x_2 - 11) + 2(x_1 + x_2^2 - 7)\n",
        "   $$\n",
        "\n",
        "\n",
        "   $$\n",
        "   \\frac{\\partial f}{\\partial x_2} = 2 (x_1^2 + x_2 - 11) + 4x_2(x_1 + x_2^2 - 7)\n",
        "   $$\n",
        "\n",
        "  Gráfico: https://www.geogebra.org/3d/g9wx3y3d\n",
        "  "
      ],
      "metadata": {
        "id": "Ff3g8tllvdcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func3(x):\n",
        "  f3 = (x[0]**2 + x[1] - 11)**2 + (x[0] + x[1]**2 - 7)**2\n",
        "  return f3\n",
        "\n",
        "def grad_3(x):\n",
        "  grad = np.zeros(2)\n",
        "  grad[0] = 4 * x[0] * (x[0]**2 + x[1] - 11) + 2 * (x[0] + x[1]**2 - 7)\n",
        "  grad[1] = 2 * (x[0]**2 + x[1] - 11) + 4 * x[1] * (x[0] + x[1]**2 - 7)\n",
        "  return grad\n",
        "\n",
        "def hess_3(x):\n",
        "  hess = np.zeros((2, 2))\n",
        "  hess[0, 0] = 12 * x[0]**2 + 4 * x[1] - 42\n",
        "  hess[0, 1] = hess[1, 0] = 4 * (x[0] + x[1])\n",
        "  hess[1, 1] = 12 * x[1]**2 + 4 * x[0] - 26\n",
        "  return hess\n"
      ],
      "metadata": {
        "id": "qB9flbVb2j56"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Busca de Armijo"
      ],
      "metadata": {
        "id": "8d8BSohOvJ8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def armijo(x, gama, d, mi):\n",
        "  t = 0.5\n",
        "  k = 0\n",
        "  d = np.array(d) #direção de descida\n",
        "  while f(x+t*d) > f(x) + mi*t*(np.transpose(gradiente(x)))@d:\n",
        "    t = gama*t\n",
        "    k = k+1\n",
        "  return t, k\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "abpBb_4uvJcu"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Método Gradiente"
      ],
      "metadata": {
        "id": "KDSf8CYDzAjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metodo_gradiente(x, gama, mi, epsilon, maxiter):\n",
        "  x=np.array(x)\n",
        "  k=0\n",
        "  i = 0   #Número de iterações\n",
        "  #while gradiente(x) != 0 :   #provavel ajuste aqui para limitar\n",
        "  while np.linalg.norm(gradiente(x)) > epsilon and i < maxiter :\n",
        "    d = -gradiente(x)\n",
        "    t, kn = armijo(x, gama, d, mi)\n",
        "    x = x + t*d\n",
        "    k = k + kn\n",
        "    i = i+1\n",
        "  return x, k, i\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ra99ne50u7tH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Método Newton\n"
      ],
      "metadata": {
        "id": "fD5gxkQn2Fyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import M\n",
        "def newton(x,gama, mi,epsilon, maxiter):\n",
        "  k=0\n",
        "  i=0  #Número de iterações\n",
        "  while np.linalg.norm(gradiente(x))> epsilon and i< maxiter :\n",
        "    d = -(np.linalg.inv(hessiana(x)))@gradiente(x)\n",
        "    t, kn = armijo(x, gama, d, mi)\n",
        "    x = x + t*d\n",
        "    k = k+kn\n",
        "    i = i+1\n",
        "  return x, k, i\n",
        "\n"
      ],
      "metadata": {
        "id": "UsFAXNjN2FCD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Método Quase-Newton"
      ],
      "metadata": {
        "id": "v-Lzt8Yc4CTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DFS(x0, x1,H): #para funções mais simples converge mais rápido\n",
        "  x0 = np.array(x0) #x antigo\n",
        "  x1 = np.array(x1) #x atual\n",
        "  p = x1-x0\n",
        "  q = gradiente(x1)-gradiente(x0)\n",
        "  if np.linalg.norm(p) != 0 and np.linalg.norm(q) != 0:\n",
        "    H = H + (p@np.transpose(p))/(np.transpose(p)@q) - (H@q@np.transpose(q)@H)/(np.transpose(q)@H@q)\n",
        "  else:\n",
        "    H = H\n",
        "  return H\n",
        "\n",
        "def BFGS__(x0, x1,H):\n",
        "  x0 = np.array(x0) #x antigo\n",
        "  x1 = np.array(x1) #x atual\n",
        "  p = x1-x0\n",
        "  q = gradiente(x1)-gradiente(x0)\n",
        "  H = H + ((1 + np.transpose(q)@H@q)/(np.transpose(p)@q))@((p@np.transpose(p))/(np.transpose(p)@q)) - (((p@np.tranpose(q)@H)+(H@q@np.transpose(p)))/(np.transpose(p)@q))\n",
        "  return H\n",
        "\n",
        "def BFGS(x0, x1, H):\n",
        "    x0 = np.array(x0)  # x antigo\n",
        "    x1 = np.array(x1)  # x atual\n",
        "    p = x1 - x0\n",
        "    q = gradiente(x1) - gradiente(x0)\n",
        "    # Ensure p and q are column vectors for matrix operations:\n",
        "    p = p.reshape(-1, 1)  # Reshape p into a column vector\n",
        "    q = q.reshape(-1, 1)  # Reshape q into a column vector\n",
        "    # Calculate terms to avoid repeated calculations and for clarity:\n",
        "    pTp = p.T @ p #transpose(p) @ p\n",
        "    p_T_q = p.T @ q #transpose(p) @ q\n",
        "    H_q = H @ q # H@q\n",
        "    q_T_H_q = q.T @ H_q #transpose(q) @ H @ q\n",
        "    # update H:\n",
        "    if p_T_q != 0: #check to avoid division by zero if p.T @ q = 0\n",
        "        H = H + (1 + q_T_H_q / p_T_q) * (np.outer(p,p.T) / p_T_q) - ((np.outer(p, (q.T @ H)) + np.outer((H_q), p.T)) / p_T_q) #outer to give matrix products as intended\n",
        "    return H\n",
        "\n",
        "def quase_newton(x, gama, mi, epsilon,t, maxiter):\n",
        "  #t é o tamnho de H segundo nossas análises\n",
        "  k=0\n",
        "  i = 0 #Número de iterações\n",
        "  H = np.identity(t) #mudar de acordo com a quantidade de variáveis\n",
        "  while np.linalg.norm(gradiente(x))> epsilon and i < maxiter:\n",
        "    d = -H@gradiente(x)\n",
        "    t, kn = armijo(x, gama, d, mi)\n",
        "    H = BFGS(x, x+t*d, H)\n",
        "    x = x + t*d\n",
        "    k = k + kn\n",
        "    i = i+1\n",
        "  return x, k,i\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VQslAL3F4BLB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradiente = grad_2\n",
        "hessiana = hess_2\n",
        "def f(x) :\n",
        "  return func2(x)\n",
        "\n",
        "#x = np.random.rand(1)\n",
        "x = np.array([-0.7])\n",
        "print(x)\n",
        "print(metodo_gradiente(x, 0.8, 0.25, 0.0001,10000))\n",
        "print(newton(x, 0.8,0.25,0.0001, 10000))\n",
        "print(quase_newton(x, 0.8, 0.25,0.0001,1,10000))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae45Qtb6tK7n",
        "outputId": "e667cd89-597a-42fa-a462-ce6e235baf0c",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.7]\n",
            "(array([-2.90353484]), 113, 17)\n",
            "(array([-0.7]), 1580000, 10000)\n",
            "(array([-2.90353534]), 0, 119)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gradiente = gradiente_2\n",
        "hessiana = hessiana_2\n",
        "def f(x) :\n",
        "  return funcao_2(x)\n",
        "\n",
        "x = np.random.rand(100)\n",
        "\n",
        "print(x)\n",
        "print(metodo_gradiente(x, 0.8 ,0.25, 0.0001,10000))\n",
        "print(newton(x, 0.8, 0.25,0.0001, 10000))\n",
        "print(quase_newton(x, 0.8, 0.25,0.000001,100, 10000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnI0XwnO0lJ7",
        "outputId": "b44cf0ee-cbca-4201-e4e9-4438cda04531",
        "collapsed": true
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.51074215 0.08509879 0.57727453 0.52356245 0.94231027 0.04357384\n",
            " 0.50552879 0.46170868 0.9987027  0.69260697 0.85815867 0.88798176\n",
            " 0.02114    0.68980149 0.45761104 0.64410848 0.96657683 0.37941224\n",
            " 0.55539899 0.71353575 0.78254408 0.86311082 0.93998099 0.41416261\n",
            " 0.30269707 0.68037879 0.62835991 0.85205988 0.92156044 0.74323191\n",
            " 0.9632032  0.27804458 0.40609545 0.05814878 0.043803   0.16380199\n",
            " 0.35096481 0.80182625 0.65121992 0.48978718 0.64203917 0.62504782\n",
            " 0.70691505 0.60357121 0.94248046 0.86036329 0.52537672 0.50299335\n",
            " 0.43496078 0.51220491 0.68847716 0.37978375 0.92241027 0.74842707\n",
            " 0.25145132 0.27505254 0.51134014 0.83822905 0.33341266 0.40240728\n",
            " 0.9211613  0.53354017 0.47129304 0.13955233 0.56408694 0.78328873\n",
            " 0.45106982 0.19637898 0.31305707 0.45598362 0.62377458 0.69949538\n",
            " 0.08381056 0.56151122 0.14319037 0.90729327 0.46746514 0.86365487\n",
            " 0.86098459 0.8915774  0.0320907  0.50001359 0.25356504 0.08559371\n",
            " 0.77321378 0.6930661  0.35970309 0.23381167 0.56461798 0.40779024\n",
            " 0.17971572 0.74575845 0.40252249 0.78784489 0.25873613 0.27398967\n",
            " 0.26020614 0.0549392  0.42356161 0.77304474]\n",
            "(array([ 2.74680277, -2.90353398,  2.74680277,  2.74680277,  2.74680277,\n",
            "       -2.90353453,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277, -2.90353453,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277, -2.90353447, -2.90353453,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277, -2.90353395,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277, -2.90353399,  2.74680277, -2.90353445,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "       -2.90353454,  2.74680277,  2.74680277, -2.90353397,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277, -2.9035345 ,  2.74680277,  2.74680277]), 150, 24)\n",
            "(array([0.51074215, 0.08509879, 0.57727453, 0.52356245, 0.94231027,\n",
            "       0.04357384, 0.50552879, 0.46170868, 0.9987027 , 0.69260697,\n",
            "       0.85815867, 0.88798176, 0.02114   , 0.68980149, 0.45761104,\n",
            "       0.64410848, 0.96657683, 0.37941224, 0.55539899, 0.71353575,\n",
            "       0.78254408, 0.86311082, 0.93998099, 0.41416261, 0.30269707,\n",
            "       0.68037879, 0.62835991, 0.85205988, 0.92156044, 0.74323191,\n",
            "       0.9632032 , 0.27804458, 0.40609545, 0.05814878, 0.043803  ,\n",
            "       0.16380199, 0.35096481, 0.80182625, 0.65121992, 0.48978718,\n",
            "       0.64203917, 0.62504782, 0.70691505, 0.60357121, 0.94248046,\n",
            "       0.86036329, 0.52537672, 0.50299335, 0.43496078, 0.51220491,\n",
            "       0.68847716, 0.37978375, 0.92241027, 0.74842707, 0.25145132,\n",
            "       0.27505254, 0.51134014, 0.83822905, 0.33341266, 0.40240728,\n",
            "       0.9211613 , 0.53354017, 0.47129304, 0.13955233, 0.56408694,\n",
            "       0.78328873, 0.45106982, 0.19637898, 0.31305707, 0.45598362,\n",
            "       0.62377458, 0.69949538, 0.08381056, 0.56151122, 0.14319037,\n",
            "       0.90729327, 0.46746514, 0.86365487, 0.86098459, 0.8915774 ,\n",
            "       0.0320907 , 0.50001359, 0.25356504, 0.08559371, 0.77321378,\n",
            "       0.6930661 , 0.35970309, 0.23381167, 0.56461798, 0.40779024,\n",
            "       0.17971572, 0.74575845, 0.40252249, 0.78784489, 0.25873613,\n",
            "       0.27398967, 0.26020614, 0.0549392 , 0.42356161, 0.77304474]), 1638874, 10000)\n",
            "(array([ 2.74680277, -2.90353403,  2.74680277,  2.74680277,  2.74680277,\n",
            "       -2.90353403,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277, -2.90353403,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680278,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680278,  2.74680277, -2.90353403, -2.90353403,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277, -2.90353403,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277, -2.90353403,  2.74680277, -2.90353403,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "       -2.90353403,  2.74680277,  2.74680277, -2.90353403,  2.74680278,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277,  2.74680277,  2.74680277,  2.74680277,\n",
            "        2.74680277,  2.74680277, -2.90353403,  2.74680277,  2.74680277]), 264, 129)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gradiente = grad_1\n",
        "hessiana = hess_1\n",
        "def f(x) :\n",
        "  return func1(x)\n",
        "x  = [3,-1]\n",
        "print(x)\n",
        "print(metodo_gradiente(x, 0.8, 0.25, 0.0001,10000))\n",
        "print(newton(x, 0.8, 0.25,0.0001,10000))\n",
        "print(quase_newton(x, 0.8, 0.25,0.0001,2,10000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFP9HeZY9xfc",
        "outputId": "3078fcc4-205a-4866-df48-9c8d64f89069"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, -1]\n",
            "(array([0.99992968, 0.99985926]), 265697, 9636)\n",
            "(array([1.00000323, 1.00000644]), 23, 19)\n",
            "(array([0.99999994, 0.99999989]), 66, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gradiente = gradiente_1\n",
        "hessiana = hesssiana_1\n",
        "def f(x):\n",
        "  return funcao_1(x)\n",
        "x = np.random.rand(7)\n",
        "x =  [0.8, 0.8, 0.8, 0.9, 0.9, 0.99, 0.99]\n",
        "print(x)\n",
        "print(metodo_gradiente(x, 0.7, 0.25, 0.0001,40000))\n",
        "#print(newton(x, 0.5, 0.25,0.0001,20000))\n",
        "#print(quase_newton(x, 0.8, 0.25,0.0001,7,10000))"
      ],
      "metadata": {
        "id": "P6sTeGsNQu5-",
        "outputId": "1392bebf-2ef3-489d-fd84-e60b93a826d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8, 0.8, 0.8, 0.9, 0.9, 0.99, 0.99]\n",
            "(array([0.82940915, 0.78198975, 0.80022798, 0.87047686, 0.90832119,\n",
            "       0.96949339, 0.98887151]), 4559830, 40000)\n"
          ]
        }
      ]
    }
  ]
}